{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import datetime,tzinfo\n",
    "from pytz import timezone\n",
    "import time\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2017-10-08\n",
       "1     2017-10-09\n",
       "2     2017-10-11\n",
       "3     2017-10-12\n",
       "4     2017-10-17\n",
       "5     2017-10-20\n",
       "6     2017-10-23\n",
       "7     2017-10-25\n",
       "8     2017-10-29\n",
       "9     2017-10-31\n",
       "10    2017-11-01\n",
       "11    2017-11-02\n",
       "12    2017-11-09\n",
       "13    2017-11-10\n",
       "14    2017-11-11\n",
       "15    2017-11-14\n",
       "16    2017-11-15\n",
       "17    2017-11-16\n",
       "18    2017-11-19\n",
       "19    2017-11-24\n",
       "20    2017-11-25\n",
       "21    2017-11-26\n",
       "22    2017-11-27\n",
       "23    2017-11-28\n",
       "24    2017-12-01\n",
       "25    2017-12-05\n",
       "26    2017-12-06\n",
       "27    2017-12-10\n",
       "28    2017-12-14\n",
       "29    2017-12-15\n",
       "30    2017-12-16\n",
       "31    2017-12-19\n",
       "32    2017-12-21\n",
       "33    2017-12-25\n",
       "34    2017-12-27\n",
       "35    2017-12-29\n",
       "36    2018-01-02\n",
       "37    2018-01-04\n",
       "38    2018-01-05\n",
       "Name: Date, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marker= pd.read_csv('marker.csv')\n",
    "marker.head()\n",
    "mark=marker['Date']\n",
    "mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2017, 10, 8, 0, 0),\n",
       " datetime.datetime(2017, 10, 9, 0, 0),\n",
       " datetime.datetime(2017, 10, 11, 0, 0),\n",
       " datetime.datetime(2017, 10, 12, 0, 0),\n",
       " datetime.datetime(2017, 10, 17, 0, 0),\n",
       " datetime.datetime(2017, 10, 20, 0, 0),\n",
       " datetime.datetime(2017, 10, 23, 0, 0),\n",
       " datetime.datetime(2017, 10, 25, 0, 0),\n",
       " datetime.datetime(2017, 10, 29, 0, 0),\n",
       " datetime.datetime(2017, 10, 31, 0, 0),\n",
       " datetime.datetime(2017, 11, 1, 0, 0),\n",
       " datetime.datetime(2017, 11, 2, 0, 0),\n",
       " datetime.datetime(2017, 11, 9, 0, 0),\n",
       " datetime.datetime(2017, 11, 10, 0, 0),\n",
       " datetime.datetime(2017, 11, 11, 0, 0),\n",
       " datetime.datetime(2017, 11, 14, 0, 0),\n",
       " datetime.datetime(2017, 11, 15, 0, 0),\n",
       " datetime.datetime(2017, 11, 16, 0, 0),\n",
       " datetime.datetime(2017, 11, 19, 0, 0),\n",
       " datetime.datetime(2017, 11, 24, 0, 0),\n",
       " datetime.datetime(2017, 11, 25, 0, 0),\n",
       " datetime.datetime(2017, 11, 26, 0, 0),\n",
       " datetime.datetime(2017, 11, 27, 0, 0),\n",
       " datetime.datetime(2017, 11, 28, 0, 0),\n",
       " datetime.datetime(2017, 12, 1, 0, 0),\n",
       " datetime.datetime(2017, 12, 5, 0, 0),\n",
       " datetime.datetime(2017, 12, 6, 0, 0),\n",
       " datetime.datetime(2017, 12, 10, 0, 0),\n",
       " datetime.datetime(2017, 12, 14, 0, 0),\n",
       " datetime.datetime(2017, 12, 15, 0, 0),\n",
       " datetime.datetime(2017, 12, 16, 0, 0),\n",
       " datetime.datetime(2017, 12, 19, 0, 0),\n",
       " datetime.datetime(2017, 12, 21, 0, 0),\n",
       " datetime.datetime(2017, 12, 25, 0, 0),\n",
       " datetime.datetime(2017, 12, 27, 0, 0),\n",
       " datetime.datetime(2017, 12, 29, 0, 0),\n",
       " datetime.datetime(2018, 1, 2, 0, 0),\n",
       " datetime.datetime(2018, 1, 4, 0, 0),\n",
       " datetime.datetime(2018, 1, 5, 0, 0)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_mark = []\n",
    "for i in range(len(mark)):\n",
    "    date = datetime.strptime(mark[i],'%Y-%m-%d')\n",
    "    array_mark.append(date)\n",
    "array_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017-10-05T00:00:00',\n",
       " '2017-10-06T00:00:00',\n",
       " '2017-10-08T00:00:00',\n",
       " '2017-10-09T00:00:00',\n",
       " '2017-10-14T00:00:00',\n",
       " '2017-10-17T00:00:00',\n",
       " '2017-10-20T00:00:00',\n",
       " '2017-10-22T00:00:00',\n",
       " '2017-10-26T00:00:00',\n",
       " '2017-10-28T00:00:00',\n",
       " '2017-10-29T00:00:00',\n",
       " '2017-10-30T00:00:00',\n",
       " '2017-11-06T00:00:00',\n",
       " '2017-11-07T00:00:00',\n",
       " '2017-11-08T00:00:00',\n",
       " '2017-11-11T00:00:00',\n",
       " '2017-11-12T00:00:00',\n",
       " '2017-11-13T00:00:00',\n",
       " '2017-11-16T00:00:00',\n",
       " '2017-11-21T00:00:00',\n",
       " '2017-11-22T00:00:00',\n",
       " '2017-11-23T00:00:00',\n",
       " '2017-11-24T00:00:00',\n",
       " '2017-11-25T00:00:00',\n",
       " '2017-11-28T00:00:00',\n",
       " '2017-12-02T00:00:00',\n",
       " '2017-12-03T00:00:00',\n",
       " '2017-12-07T00:00:00',\n",
       " '2017-12-11T00:00:00',\n",
       " '2017-12-12T00:00:00',\n",
       " '2017-12-13T00:00:00',\n",
       " '2017-12-16T00:00:00',\n",
       " '2017-12-18T00:00:00',\n",
       " '2017-12-22T00:00:00',\n",
       " '2017-12-24T00:00:00',\n",
       " '2017-12-26T00:00:00',\n",
       " '2017-12-30T00:00:00',\n",
       " '2018-01-01T00:00:00',\n",
       " '2018-01-02T00:00:00']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 3\n",
    "days_before=[]\n",
    "days_after=[]\n",
    "for i in range(len(mark)):\n",
    "    date = datetime.strptime(mark[i],'%Y-%m-%d')\n",
    "    days_before.append((date-timedelta(days=N)).isoformat())\n",
    "    days_after.append((date+timedelta(days=N)).isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2017, 10, 8, 0, 0),\n",
       " datetime.datetime(2017, 10, 9, 0, 0),\n",
       " datetime.datetime(2017, 10, 11, 0, 0),\n",
       " datetime.datetime(2017, 10, 12, 0, 0),\n",
       " datetime.datetime(2017, 10, 17, 0, 0),\n",
       " datetime.datetime(2017, 10, 20, 0, 0),\n",
       " datetime.datetime(2017, 10, 23, 0, 0),\n",
       " datetime.datetime(2017, 10, 25, 0, 0),\n",
       " datetime.datetime(2017, 10, 29, 0, 0),\n",
       " datetime.datetime(2017, 10, 31, 0, 0),\n",
       " datetime.datetime(2017, 11, 1, 0, 0),\n",
       " datetime.datetime(2017, 11, 2, 0, 0),\n",
       " datetime.datetime(2017, 11, 9, 0, 0),\n",
       " datetime.datetime(2017, 11, 10, 0, 0),\n",
       " datetime.datetime(2017, 11, 11, 0, 0),\n",
       " datetime.datetime(2017, 11, 14, 0, 0),\n",
       " datetime.datetime(2017, 11, 15, 0, 0),\n",
       " datetime.datetime(2017, 11, 16, 0, 0),\n",
       " datetime.datetime(2017, 11, 19, 0, 0),\n",
       " datetime.datetime(2017, 11, 24, 0, 0),\n",
       " datetime.datetime(2017, 11, 25, 0, 0),\n",
       " datetime.datetime(2017, 11, 26, 0, 0),\n",
       " datetime.datetime(2017, 11, 27, 0, 0),\n",
       " datetime.datetime(2017, 11, 28, 0, 0),\n",
       " datetime.datetime(2017, 12, 1, 0, 0),\n",
       " datetime.datetime(2017, 12, 5, 0, 0),\n",
       " datetime.datetime(2017, 12, 6, 0, 0),\n",
       " datetime.datetime(2017, 12, 10, 0, 0),\n",
       " datetime.datetime(2017, 12, 14, 0, 0),\n",
       " datetime.datetime(2017, 12, 15, 0, 0),\n",
       " datetime.datetime(2017, 12, 16, 0, 0),\n",
       " datetime.datetime(2017, 12, 19, 0, 0),\n",
       " datetime.datetime(2017, 12, 21, 0, 0),\n",
       " datetime.datetime(2017, 12, 25, 0, 0),\n",
       " datetime.datetime(2017, 12, 27, 0, 0),\n",
       " datetime.datetime(2017, 12, 29, 0, 0),\n",
       " datetime.datetime(2018, 1, 2, 0, 0),\n",
       " datetime.datetime(2018, 1, 4, 0, 0),\n",
       " datetime.datetime(2018, 1, 5, 0, 0),\n",
       " datetime.datetime(2017, 10, 7, 0, 0),\n",
       " datetime.datetime(2017, 10, 9, 0, 0),\n",
       " datetime.datetime(2017, 10, 6, 0, 0),\n",
       " datetime.datetime(2017, 10, 10, 0, 0),\n",
       " datetime.datetime(2017, 10, 5, 0, 0),\n",
       " datetime.datetime(2017, 10, 11, 0, 0),\n",
       " datetime.datetime(2017, 10, 8, 0, 0),\n",
       " datetime.datetime(2017, 10, 10, 0, 0),\n",
       " datetime.datetime(2017, 10, 7, 0, 0),\n",
       " datetime.datetime(2017, 10, 11, 0, 0),\n",
       " datetime.datetime(2017, 10, 6, 0, 0),\n",
       " datetime.datetime(2017, 10, 12, 0, 0),\n",
       " datetime.datetime(2017, 10, 10, 0, 0),\n",
       " datetime.datetime(2017, 10, 12, 0, 0),\n",
       " datetime.datetime(2017, 10, 9, 0, 0),\n",
       " datetime.datetime(2017, 10, 13, 0, 0),\n",
       " datetime.datetime(2017, 10, 8, 0, 0),\n",
       " datetime.datetime(2017, 10, 14, 0, 0),\n",
       " datetime.datetime(2017, 10, 11, 0, 0),\n",
       " datetime.datetime(2017, 10, 13, 0, 0),\n",
       " datetime.datetime(2017, 10, 10, 0, 0),\n",
       " datetime.datetime(2017, 10, 14, 0, 0),\n",
       " datetime.datetime(2017, 10, 9, 0, 0),\n",
       " datetime.datetime(2017, 10, 15, 0, 0),\n",
       " datetime.datetime(2017, 10, 16, 0, 0),\n",
       " datetime.datetime(2017, 10, 18, 0, 0),\n",
       " datetime.datetime(2017, 10, 15, 0, 0),\n",
       " datetime.datetime(2017, 10, 19, 0, 0),\n",
       " datetime.datetime(2017, 10, 14, 0, 0),\n",
       " datetime.datetime(2017, 10, 20, 0, 0),\n",
       " datetime.datetime(2017, 10, 19, 0, 0),\n",
       " datetime.datetime(2017, 10, 21, 0, 0),\n",
       " datetime.datetime(2017, 10, 18, 0, 0),\n",
       " datetime.datetime(2017, 10, 22, 0, 0),\n",
       " datetime.datetime(2017, 10, 17, 0, 0),\n",
       " datetime.datetime(2017, 10, 23, 0, 0),\n",
       " datetime.datetime(2017, 10, 22, 0, 0),\n",
       " datetime.datetime(2017, 10, 24, 0, 0),\n",
       " datetime.datetime(2017, 10, 21, 0, 0),\n",
       " datetime.datetime(2017, 10, 25, 0, 0),\n",
       " datetime.datetime(2017, 10, 20, 0, 0),\n",
       " datetime.datetime(2017, 10, 26, 0, 0),\n",
       " datetime.datetime(2017, 10, 24, 0, 0),\n",
       " datetime.datetime(2017, 10, 26, 0, 0),\n",
       " datetime.datetime(2017, 10, 23, 0, 0),\n",
       " datetime.datetime(2017, 10, 27, 0, 0),\n",
       " datetime.datetime(2017, 10, 22, 0, 0),\n",
       " datetime.datetime(2017, 10, 28, 0, 0),\n",
       " datetime.datetime(2017, 10, 28, 0, 0),\n",
       " datetime.datetime(2017, 10, 30, 0, 0),\n",
       " datetime.datetime(2017, 10, 27, 0, 0),\n",
       " datetime.datetime(2017, 10, 31, 0, 0),\n",
       " datetime.datetime(2017, 10, 26, 0, 0),\n",
       " datetime.datetime(2017, 11, 1, 0, 0),\n",
       " datetime.datetime(2017, 10, 30, 0, 0),\n",
       " datetime.datetime(2017, 11, 1, 0, 0),\n",
       " datetime.datetime(2017, 10, 29, 0, 0),\n",
       " datetime.datetime(2017, 11, 2, 0, 0),\n",
       " datetime.datetime(2017, 10, 28, 0, 0),\n",
       " datetime.datetime(2017, 11, 3, 0, 0),\n",
       " datetime.datetime(2017, 10, 31, 0, 0),\n",
       " datetime.datetime(2017, 11, 2, 0, 0),\n",
       " datetime.datetime(2017, 10, 30, 0, 0),\n",
       " datetime.datetime(2017, 11, 3, 0, 0),\n",
       " datetime.datetime(2017, 10, 29, 0, 0),\n",
       " datetime.datetime(2017, 11, 4, 0, 0),\n",
       " datetime.datetime(2017, 11, 1, 0, 0),\n",
       " datetime.datetime(2017, 11, 3, 0, 0),\n",
       " datetime.datetime(2017, 10, 31, 0, 0),\n",
       " datetime.datetime(2017, 11, 4, 0, 0),\n",
       " datetime.datetime(2017, 10, 30, 0, 0),\n",
       " datetime.datetime(2017, 11, 5, 0, 0),\n",
       " datetime.datetime(2017, 11, 8, 0, 0),\n",
       " datetime.datetime(2017, 11, 10, 0, 0),\n",
       " datetime.datetime(2017, 11, 7, 0, 0),\n",
       " datetime.datetime(2017, 11, 11, 0, 0),\n",
       " datetime.datetime(2017, 11, 6, 0, 0),\n",
       " datetime.datetime(2017, 11, 12, 0, 0),\n",
       " datetime.datetime(2017, 11, 9, 0, 0),\n",
       " datetime.datetime(2017, 11, 11, 0, 0),\n",
       " datetime.datetime(2017, 11, 8, 0, 0),\n",
       " datetime.datetime(2017, 11, 12, 0, 0),\n",
       " datetime.datetime(2017, 11, 7, 0, 0),\n",
       " datetime.datetime(2017, 11, 13, 0, 0),\n",
       " datetime.datetime(2017, 11, 10, 0, 0),\n",
       " datetime.datetime(2017, 11, 12, 0, 0),\n",
       " datetime.datetime(2017, 11, 9, 0, 0),\n",
       " datetime.datetime(2017, 11, 13, 0, 0),\n",
       " datetime.datetime(2017, 11, 8, 0, 0),\n",
       " datetime.datetime(2017, 11, 14, 0, 0),\n",
       " datetime.datetime(2017, 11, 13, 0, 0),\n",
       " datetime.datetime(2017, 11, 15, 0, 0),\n",
       " datetime.datetime(2017, 11, 12, 0, 0),\n",
       " datetime.datetime(2017, 11, 16, 0, 0),\n",
       " datetime.datetime(2017, 11, 11, 0, 0),\n",
       " datetime.datetime(2017, 11, 17, 0, 0),\n",
       " datetime.datetime(2017, 11, 14, 0, 0),\n",
       " datetime.datetime(2017, 11, 16, 0, 0),\n",
       " datetime.datetime(2017, 11, 13, 0, 0),\n",
       " datetime.datetime(2017, 11, 17, 0, 0),\n",
       " datetime.datetime(2017, 11, 12, 0, 0),\n",
       " datetime.datetime(2017, 11, 18, 0, 0),\n",
       " datetime.datetime(2017, 11, 15, 0, 0),\n",
       " datetime.datetime(2017, 11, 17, 0, 0),\n",
       " datetime.datetime(2017, 11, 14, 0, 0),\n",
       " datetime.datetime(2017, 11, 18, 0, 0),\n",
       " datetime.datetime(2017, 11, 13, 0, 0),\n",
       " datetime.datetime(2017, 11, 19, 0, 0),\n",
       " datetime.datetime(2017, 11, 18, 0, 0),\n",
       " datetime.datetime(2017, 11, 20, 0, 0),\n",
       " datetime.datetime(2017, 11, 17, 0, 0),\n",
       " datetime.datetime(2017, 11, 21, 0, 0),\n",
       " datetime.datetime(2017, 11, 16, 0, 0),\n",
       " datetime.datetime(2017, 11, 22, 0, 0),\n",
       " datetime.datetime(2017, 11, 23, 0, 0),\n",
       " datetime.datetime(2017, 11, 25, 0, 0),\n",
       " datetime.datetime(2017, 11, 22, 0, 0),\n",
       " datetime.datetime(2017, 11, 26, 0, 0),\n",
       " datetime.datetime(2017, 11, 21, 0, 0),\n",
       " datetime.datetime(2017, 11, 27, 0, 0),\n",
       " datetime.datetime(2017, 11, 24, 0, 0),\n",
       " datetime.datetime(2017, 11, 26, 0, 0),\n",
       " datetime.datetime(2017, 11, 23, 0, 0),\n",
       " datetime.datetime(2017, 11, 27, 0, 0),\n",
       " datetime.datetime(2017, 11, 22, 0, 0),\n",
       " datetime.datetime(2017, 11, 28, 0, 0),\n",
       " datetime.datetime(2017, 11, 25, 0, 0),\n",
       " datetime.datetime(2017, 11, 27, 0, 0),\n",
       " datetime.datetime(2017, 11, 24, 0, 0),\n",
       " datetime.datetime(2017, 11, 28, 0, 0),\n",
       " datetime.datetime(2017, 11, 23, 0, 0),\n",
       " datetime.datetime(2017, 11, 29, 0, 0),\n",
       " datetime.datetime(2017, 11, 26, 0, 0),\n",
       " datetime.datetime(2017, 11, 28, 0, 0),\n",
       " datetime.datetime(2017, 11, 25, 0, 0),\n",
       " datetime.datetime(2017, 11, 29, 0, 0),\n",
       " datetime.datetime(2017, 11, 24, 0, 0),\n",
       " datetime.datetime(2017, 11, 30, 0, 0),\n",
       " datetime.datetime(2017, 11, 27, 0, 0),\n",
       " datetime.datetime(2017, 11, 29, 0, 0),\n",
       " datetime.datetime(2017, 11, 26, 0, 0),\n",
       " datetime.datetime(2017, 11, 30, 0, 0),\n",
       " datetime.datetime(2017, 11, 25, 0, 0),\n",
       " datetime.datetime(2017, 12, 1, 0, 0),\n",
       " datetime.datetime(2017, 11, 30, 0, 0),\n",
       " datetime.datetime(2017, 12, 2, 0, 0),\n",
       " datetime.datetime(2017, 11, 29, 0, 0),\n",
       " datetime.datetime(2017, 12, 3, 0, 0),\n",
       " datetime.datetime(2017, 11, 28, 0, 0),\n",
       " datetime.datetime(2017, 12, 4, 0, 0),\n",
       " datetime.datetime(2017, 12, 4, 0, 0),\n",
       " datetime.datetime(2017, 12, 6, 0, 0),\n",
       " datetime.datetime(2017, 12, 3, 0, 0),\n",
       " datetime.datetime(2017, 12, 7, 0, 0),\n",
       " datetime.datetime(2017, 12, 2, 0, 0),\n",
       " datetime.datetime(2017, 12, 8, 0, 0),\n",
       " datetime.datetime(2017, 12, 5, 0, 0),\n",
       " datetime.datetime(2017, 12, 7, 0, 0),\n",
       " datetime.datetime(2017, 12, 4, 0, 0),\n",
       " datetime.datetime(2017, 12, 8, 0, 0),\n",
       " datetime.datetime(2017, 12, 3, 0, 0),\n",
       " datetime.datetime(2017, 12, 9, 0, 0),\n",
       " datetime.datetime(2017, 12, 9, 0, 0),\n",
       " datetime.datetime(2017, 12, 11, 0, 0),\n",
       " datetime.datetime(2017, 12, 8, 0, 0),\n",
       " datetime.datetime(2017, 12, 12, 0, 0),\n",
       " datetime.datetime(2017, 12, 7, 0, 0),\n",
       " datetime.datetime(2017, 12, 13, 0, 0),\n",
       " datetime.datetime(2017, 12, 13, 0, 0),\n",
       " datetime.datetime(2017, 12, 15, 0, 0),\n",
       " datetime.datetime(2017, 12, 12, 0, 0),\n",
       " datetime.datetime(2017, 12, 16, 0, 0),\n",
       " datetime.datetime(2017, 12, 11, 0, 0),\n",
       " datetime.datetime(2017, 12, 17, 0, 0),\n",
       " datetime.datetime(2017, 12, 14, 0, 0),\n",
       " datetime.datetime(2017, 12, 16, 0, 0),\n",
       " datetime.datetime(2017, 12, 13, 0, 0),\n",
       " datetime.datetime(2017, 12, 17, 0, 0),\n",
       " datetime.datetime(2017, 12, 12, 0, 0),\n",
       " datetime.datetime(2017, 12, 18, 0, 0),\n",
       " datetime.datetime(2017, 12, 15, 0, 0),\n",
       " datetime.datetime(2017, 12, 17, 0, 0),\n",
       " datetime.datetime(2017, 12, 14, 0, 0),\n",
       " datetime.datetime(2017, 12, 18, 0, 0),\n",
       " datetime.datetime(2017, 12, 13, 0, 0),\n",
       " datetime.datetime(2017, 12, 19, 0, 0),\n",
       " datetime.datetime(2017, 12, 18, 0, 0),\n",
       " datetime.datetime(2017, 12, 20, 0, 0),\n",
       " datetime.datetime(2017, 12, 17, 0, 0),\n",
       " datetime.datetime(2017, 12, 21, 0, 0),\n",
       " datetime.datetime(2017, 12, 16, 0, 0),\n",
       " datetime.datetime(2017, 12, 22, 0, 0),\n",
       " datetime.datetime(2017, 12, 20, 0, 0),\n",
       " datetime.datetime(2017, 12, 22, 0, 0),\n",
       " datetime.datetime(2017, 12, 19, 0, 0),\n",
       " datetime.datetime(2017, 12, 23, 0, 0),\n",
       " datetime.datetime(2017, 12, 18, 0, 0),\n",
       " datetime.datetime(2017, 12, 24, 0, 0),\n",
       " datetime.datetime(2017, 12, 24, 0, 0),\n",
       " datetime.datetime(2017, 12, 26, 0, 0),\n",
       " datetime.datetime(2017, 12, 23, 0, 0),\n",
       " datetime.datetime(2017, 12, 27, 0, 0),\n",
       " datetime.datetime(2017, 12, 22, 0, 0),\n",
       " datetime.datetime(2017, 12, 28, 0, 0),\n",
       " datetime.datetime(2017, 12, 26, 0, 0),\n",
       " datetime.datetime(2017, 12, 28, 0, 0),\n",
       " datetime.datetime(2017, 12, 25, 0, 0),\n",
       " datetime.datetime(2017, 12, 29, 0, 0),\n",
       " datetime.datetime(2017, 12, 24, 0, 0),\n",
       " datetime.datetime(2017, 12, 30, 0, 0),\n",
       " datetime.datetime(2017, 12, 28, 0, 0),\n",
       " datetime.datetime(2017, 12, 30, 0, 0),\n",
       " datetime.datetime(2017, 12, 27, 0, 0),\n",
       " datetime.datetime(2017, 12, 31, 0, 0),\n",
       " datetime.datetime(2017, 12, 26, 0, 0),\n",
       " datetime.datetime(2018, 1, 1, 0, 0),\n",
       " datetime.datetime(2018, 1, 1, 0, 0),\n",
       " datetime.datetime(2018, 1, 3, 0, 0),\n",
       " datetime.datetime(2017, 12, 31, 0, 0),\n",
       " datetime.datetime(2018, 1, 4, 0, 0),\n",
       " datetime.datetime(2017, 12, 30, 0, 0),\n",
       " datetime.datetime(2018, 1, 5, 0, 0),\n",
       " datetime.datetime(2018, 1, 3, 0, 0),\n",
       " datetime.datetime(2018, 1, 5, 0, 0),\n",
       " datetime.datetime(2018, 1, 2, 0, 0),\n",
       " datetime.datetime(2018, 1, 6, 0, 0),\n",
       " datetime.datetime(2018, 1, 1, 0, 0),\n",
       " datetime.datetime(2018, 1, 7, 0, 0),\n",
       " datetime.datetime(2018, 1, 4, 0, 0),\n",
       " datetime.datetime(2018, 1, 6, 0, 0),\n",
       " datetime.datetime(2018, 1, 3, 0, 0),\n",
       " datetime.datetime(2018, 1, 7, 0, 0),\n",
       " datetime.datetime(2018, 1, 2, 0, 0),\n",
       " datetime.datetime(2018, 1, 8, 0, 0)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(mark)):\n",
    "    date = datetime.strptime(mark[i],'%Y-%m-%d')\n",
    "    array_mark.append(date-timedelta(days=1))\n",
    "    array_mark.append(date+timedelta(days=1))\n",
    "    array_mark.append(date-timedelta(days=2))\n",
    "    array_mark.append(date+timedelta(days=2))\n",
    "    array_mark.append(date-timedelta(days=3))\n",
    "    array_mark.append(date+timedelta(days=3))\n",
    "array_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_mark=pd.DataFrame({'Date':array_mark,\n",
    "                       'Mark':np.ones(len(array_mark))})\n",
    "date_mark.head()\n",
    "date_mark.to_csv('marked_dates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv('short')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>contents</th>\n",
       "      <th>description</th>\n",
       "      <th>publisher</th>\n",
       "      <th>source_url</th>\n",
       "      <th>title</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Phillip Molnar</td>\n",
       "      <td>A British real estate company Monday launched ...</td>\n",
       "      <td>A British real estate company Monday launched ...</td>\n",
       "      <td>Sandiegouniontribune.com</td>\n",
       "      <td>http://www.sandiegouniontribune.com/business/r...</td>\n",
       "      <td>Purplebricks, flat fee real estate listers, la...</td>\n",
       "      <td>2018-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-09 —   bbc.com\\t\\n\\t\\nsource article |...</td>\n",
       "      <td>``In parts of the continent - especially comme...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Why African millennials can't get enough of Bi...</td>\n",
       "      <td>2018-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Associated Press, By Associated Press</td>\n",
       "      <td>NEW YORK — Kodak, which traces its roots to th...</td>\n",
       "      <td>NEW YORK — Kodak, which traces its roots to th...</td>\n",
       "      <td>Bostonherald.com</td>\n",
       "      <td>http://www.bostonherald.com/news/national/2018...</td>\n",
       "      <td>Kodak surges at it becomes latest 'cryptocurre...</td>\n",
       "      <td>2018-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-09 —   thehill.com\\t\\n\\t\\nsource artic...</td>\n",
       "      <td>``JPMorgan Chase CEO Jamie Dimon has walked ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dimon: \"I regret calling bitcoin a fraud\"</td>\n",
       "      <td>2018-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-09 —   reuters.com\\t\\n\\t\\nsource artic...</td>\n",
       "      <td>``Staff at the regulatory agency \"expressed co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fund managers say bitcoin ETF proposals withdr...</td>\n",
       "      <td>2018-01-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                 author  \\\n",
       "0           0                         Phillip Molnar   \n",
       "1           1                                    NaN   \n",
       "2           2  Associated Press, By Associated Press   \n",
       "3           3                                    NaN   \n",
       "4           4                                    NaN   \n",
       "\n",
       "                                            contents  \\\n",
       "0  A British real estate company Monday launched ...   \n",
       "1  2018-01-09 —   bbc.com\\t\\n\\t\\nsource article |...   \n",
       "2  NEW YORK — Kodak, which traces its roots to th...   \n",
       "3  2018-01-09 —   thehill.com\\t\\n\\t\\nsource artic...   \n",
       "4  2018-01-09 —   reuters.com\\t\\n\\t\\nsource artic...   \n",
       "\n",
       "                                         description  \\\n",
       "0  A British real estate company Monday launched ...   \n",
       "1  ``In parts of the continent - especially comme...   \n",
       "2  NEW YORK — Kodak, which traces its roots to th...   \n",
       "3  ``JPMorgan Chase CEO Jamie Dimon has walked ba...   \n",
       "4  ``Staff at the regulatory agency \"expressed co...   \n",
       "\n",
       "                  publisher  \\\n",
       "0  Sandiegouniontribune.com   \n",
       "1                       NaN   \n",
       "2          Bostonherald.com   \n",
       "3                       NaN   \n",
       "4                       NaN   \n",
       "\n",
       "                                          source_url  \\\n",
       "0  http://www.sandiegouniontribune.com/business/r...   \n",
       "1                                                NaN   \n",
       "2  http://www.bostonherald.com/news/national/2018...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                               title        Date  \n",
       "0  Purplebricks, flat fee real estate listers, la...  2018-01-09  \n",
       "1  Why African millennials can't get enough of Bi...  2018-01-09  \n",
       "2  Kodak surges at it becomes latest 'cryptocurre...  2018-01-09  \n",
       "3          Dimon: \"I regret calling bitcoin a fraud\"  2018-01-09  \n",
       "4  Fund managers say bitcoin ETF proposals withdr...  2018-01-09  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert Timestamp into separate Date and Time\n",
    "#temp = pd.DatetimeIndex(df['Timestamp']) #Gather all datetime objects\n",
    "df['Date'] = pd.to_datetime(df['timeStamp']).dt.date\n",
    "\n",
    "del df['timeStamp'] #Delete original datetime column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.Date = df.Date.astype(str)\n",
    "date_mark.Date = date_mark.Date.astype(str)\n",
    "marked = pd.merge(df,date_mark, how='left', left_on='Date',right_on='Date')\n",
    "#df.merge(date_mark,how='left',left_on='Date',right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marked.Mark = marked.Mark.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>contents</th>\n",
       "      <th>description</th>\n",
       "      <th>publisher</th>\n",
       "      <th>source_url</th>\n",
       "      <th>title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Mark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Phillip Molnar</td>\n",
       "      <td>A British real estate company Monday launched ...</td>\n",
       "      <td>A British real estate company Monday launched ...</td>\n",
       "      <td>Sandiegouniontribune.com</td>\n",
       "      <td>http://www.sandiegouniontribune.com/business/r...</td>\n",
       "      <td>Purplebricks, flat fee real estate listers, la...</td>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-09 —   bbc.com\\t\\n\\t\\nsource article |...</td>\n",
       "      <td>``In parts of the continent - especially comme...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Why African millennials can't get enough of Bi...</td>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Associated Press, By Associated Press</td>\n",
       "      <td>NEW YORK — Kodak, which traces its roots to th...</td>\n",
       "      <td>NEW YORK — Kodak, which traces its roots to th...</td>\n",
       "      <td>Bostonherald.com</td>\n",
       "      <td>http://www.bostonherald.com/news/national/2018...</td>\n",
       "      <td>Kodak surges at it becomes latest 'cryptocurre...</td>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-09 —   thehill.com\\t\\n\\t\\nsource artic...</td>\n",
       "      <td>``JPMorgan Chase CEO Jamie Dimon has walked ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dimon: \"I regret calling bitcoin a fraud\"</td>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-09 —   reuters.com\\t\\n\\t\\nsource artic...</td>\n",
       "      <td>``Staff at the regulatory agency \"expressed co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fund managers say bitcoin ETF proposals withdr...</td>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                 author  \\\n",
       "0           0                         Phillip Molnar   \n",
       "1           1                                    NaN   \n",
       "2           2  Associated Press, By Associated Press   \n",
       "3           3                                    NaN   \n",
       "4           4                                    NaN   \n",
       "\n",
       "                                            contents  \\\n",
       "0  A British real estate company Monday launched ...   \n",
       "1  2018-01-09 —   bbc.com\\t\\n\\t\\nsource article |...   \n",
       "2  NEW YORK — Kodak, which traces its roots to th...   \n",
       "3  2018-01-09 —   thehill.com\\t\\n\\t\\nsource artic...   \n",
       "4  2018-01-09 —   reuters.com\\t\\n\\t\\nsource artic...   \n",
       "\n",
       "                                         description  \\\n",
       "0  A British real estate company Monday launched ...   \n",
       "1  ``In parts of the continent - especially comme...   \n",
       "2  NEW YORK — Kodak, which traces its roots to th...   \n",
       "3  ``JPMorgan Chase CEO Jamie Dimon has walked ba...   \n",
       "4  ``Staff at the regulatory agency \"expressed co...   \n",
       "\n",
       "                  publisher  \\\n",
       "0  Sandiegouniontribune.com   \n",
       "1                       NaN   \n",
       "2          Bostonherald.com   \n",
       "3                       NaN   \n",
       "4                       NaN   \n",
       "\n",
       "                                          source_url  \\\n",
       "0  http://www.sandiegouniontribune.com/business/r...   \n",
       "1                                                NaN   \n",
       "2  http://www.bostonherald.com/news/national/2018...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                               title        Date  Mark  \n",
       "0  Purplebricks, flat fee real estate listers, la...  2018-01-09   0.0  \n",
       "1  Why African millennials can't get enough of Bi...  2018-01-09   0.0  \n",
       "2  Kodak surges at it becomes latest 'cryptocurre...  2018-01-09   0.0  \n",
       "3          Dimon: \"I regret calling bitcoin a fraud\"  2018-01-09   0.0  \n",
       "4  Fund managers say bitcoin ETF proposals withdr...  2018-01-09   0.0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marked.to_csv('marked_news_short.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
