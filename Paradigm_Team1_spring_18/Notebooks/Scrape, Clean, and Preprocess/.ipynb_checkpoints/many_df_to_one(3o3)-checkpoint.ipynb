{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Packages and Libraries ##\n",
    "\n",
    "# DataFrames and math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Output related packages \n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stretch Jupyter coding blocks to fit screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\")) \n",
    "\n",
    "# make it run on py2 and py3\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Merging and Clean Up\n",
    "This  notebook is intended to perform the following processes:\n",
    "\n",
    "    1.1 Read-in multiple dataframes. Each dataframe is the sorted and cleaned\n",
    "\n",
    "    1.2 Indiviual dataframes are concatenated into a single dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "___\n",
    "### **Begin Data Merging and Clean Up:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Merging and Cleaning Functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_sort(df):\n",
    "    \"\"\" \n",
    "    Accepts: dataframe\n",
    "    Procedure: ascending sort by timeStamp  -- placing missing data at top\n",
    "    Returns: dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    result = df.sort_values(by = 'timeStamp', ascending = True,  na_position='first')\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_dropDuplicates(df):\n",
    "    \"\"\" \n",
    "    Accepts: dataframe \n",
    "    Procedure: for every row, checks every column - drops the second identical row \n",
    "    Returns: dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    result = df.drop_duplicates(keep = 'first')\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_concat(df_list):\n",
    "    \"\"\" \n",
    "    Accepts: a list of dataframe references\n",
    "    Procedure: concatenates dataframes, ignoring index\n",
    "    Returns: dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    result = pd.concat(df_list, ignore_index=True)\n",
    "    print(result.info(), \"\\n\")\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Control function for merging and cleaning__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_clean(df_list):\n",
    "    \"\"\" \n",
    "    Accepts: a list of dataframe references\n",
    "    Procedure: for each list element (df reference) it (1) sorts df by date, (2) removes duplicate rows\n",
    "    Returns: dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    temp = pd.DataFrame()\n",
    "    i = 1\n",
    "    for df in df_list:\n",
    "        sort = df_sort(df)                # sorts dataframe\n",
    "        print(\"\\nDataframe\", str(i),\"sorted by 'timeStamp'.\")\n",
    "        \n",
    "        rm_dups = df_dropDuplicates(sort) # removes duplicate rows from dataframe\n",
    "        print(\"Duplicate rows dropped from dataFrame \", str(i))\n",
    "        \n",
    "        temp = temp.append(rm_dups)       # creates list of dataframe references\n",
    "        i += 1\n",
    "        \n",
    "    print(\"\\n+++ Dataframes Concatenated +++\\n\\n\")\n",
    "    processed = df_concat([temp])         # pd.concat requires a list of dataframes\n",
    "    \n",
    "    # check distribution of features\n",
    "    print(\"\\nDATAFRAME FEATURE OVERVIEW\\n\")\n",
    "    for key in processed:\n",
    "        print(\"\\tFeature: \",key,\" \\t  contains \",len(processed[key].unique()),\"unique values.\")\n",
    "    \n",
    "    print(\"\\n\\n\\t\\t\\t+++++++++++++++++++++\\n\",\n",
    "          \"\\t\\t\\t+ PROCESS COMPLETED +\\n\", \n",
    "          \"\\t\\t\\t+++++++++++++++++++++\")\n",
    "    \n",
    "    return(processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__Process: riskEx_df__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'contents', 'description', 'publisher', 'source_url',\n",
       "       'timeStamp', 'title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data \n",
    "rEx1 = pd.read_csv('riskEx_df.csv')\n",
    "rEx2 = pd.read_csv('riskEx_df2.csv')\n",
    "rEx3 = pd.read_csv('riskEx_df3.csv')\n",
    "rEx4 = pd.read_csv('riskEx_df4.csv')\n",
    "rEx5 = pd.read_csv('riskEx_df5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list stores dataframe references for iteration\n",
    "all_rEx = [rEx1, rEx2, rEx3, rEx4, rEx5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataframe 1 sorted by 'timeStamp'.\n",
      "Duplicate rows dropped from dataFrame  1\n",
      "\n",
      "Dataframe 2 sorted by 'timeStamp'.\n",
      "Duplicate rows dropped from dataFrame  2\n",
      "\n",
      "Dataframe 3 sorted by 'timeStamp'.\n",
      "Duplicate rows dropped from dataFrame  3\n",
      "\n",
      "Dataframe 4 sorted by 'timeStamp'.\n",
      "Duplicate rows dropped from dataFrame  4\n",
      "\n",
      "Dataframe 5 sorted by 'timeStamp'.\n",
      "Duplicate rows dropped from dataFrame  5\n",
      "\n",
      "+++ Dataframes Concatenated +++\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37582 entries, 0 to 37581\n",
      "Data columns (total 7 columns):\n",
      "author         37378 non-null object\n",
      "contents       37582 non-null object\n",
      "description    37368 non-null object\n",
      "publisher      37582 non-null object\n",
      "source_url     37582 non-null object\n",
      "timeStamp      37582 non-null object\n",
      "title          37571 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 2.0+ MB\n",
      "None \n",
      "\n",
      "\n",
      "DATAFRAME FEATURE OVERVIEW\n",
      "\n",
      "\tFeature:  author  \t  contains  8110 unique values.\n",
      "\tFeature:  contents  \t  contains  28561 unique values.\n",
      "\tFeature:  description  \t  contains  31161 unique values.\n",
      "\tFeature:  publisher  \t  contains  1944 unique values.\n",
      "\tFeature:  source_url  \t  contains  36156 unique values.\n",
      "\tFeature:  timeStamp  \t  contains  33139 unique values.\n",
      "\tFeature:  title  \t  contains  31109 unique values.\n",
      "\n",
      "\n",
      "\t\t\t+++++++++++++++++++++\n",
      " \t\t\t+ PROCESS COMPLETED +\n",
      " \t\t\t+++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "# object declared stores resultincleaned, sorted and concatenated df\n",
    "r_Ex = merge_and_clean(all_rEx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting of concatenated df\n",
    "r_Ex_sort = df_sort(r_Ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops duplicate rows from concatenated df\n",
    "rEx = df_dropDuplicates(r_Ex_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>contents</th>\n",
       "      <th>description</th>\n",
       "      <th>publisher</th>\n",
       "      <th>source_url</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36261</td>\n",
       "      <td>36458</td>\n",
       "      <td>36251</td>\n",
       "      <td>36458</td>\n",
       "      <td>36458</td>\n",
       "      <td>36458</td>\n",
       "      <td>36447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>8109</td>\n",
       "      <td>28561</td>\n",
       "      <td>31160</td>\n",
       "      <td>1944</td>\n",
       "      <td>36156</td>\n",
       "      <td>33139</td>\n",
       "      <td>31108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Scott Scanlon</td>\n",
       "      <td>403 Forbidden</td>\n",
       "      <td>The Internet on one page. Successor of Popurls...</td>\n",
       "      <td>Youbrandinc.com</td>\n",
       "      <td>http://www.startribune.com/twitter-to-ban-cryp...</td>\n",
       "      <td>2018-02-27 17:00:50+00:00</td>\n",
       "      <td>6 things Australian traders will be talking ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1731</td>\n",
       "      <td>4608</td>\n",
       "      <td>742</td>\n",
       "      <td>1718</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author       contents  \\\n",
       "count           36261          36458   \n",
       "unique           8109          28561   \n",
       "top     Scott Scanlon  403 Forbidden   \n",
       "freq             1731           4608   \n",
       "\n",
       "                                              description        publisher  \\\n",
       "count                                               36251            36458   \n",
       "unique                                              31160             1944   \n",
       "top     The Internet on one page. Successor of Popurls...  Youbrandinc.com   \n",
       "freq                                                  742             1718   \n",
       "\n",
       "                                               source_url  \\\n",
       "count                                               36458   \n",
       "unique                                              36156   \n",
       "top     http://www.startribune.com/twitter-to-ban-cryp...   \n",
       "freq                                                    4   \n",
       "\n",
       "                        timeStamp  \\\n",
       "count                       36458   \n",
       "unique                      33139   \n",
       "top     2018-02-27 17:00:50+00:00   \n",
       "freq                           12   \n",
       "\n",
       "                                                    title  \n",
       "count                                               36447  \n",
       "unique                                              31108  \n",
       "top     6 things Australian traders will be talking ab...  \n",
       "freq                                                   43  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe overview\n",
    "rEx.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Write to csv__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "rEx.to_csv('rEx_df.csv', index_label = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__Process: use_riskEx__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "use_rEx1 = pd.read_csv('use_riskEx.csv')\n",
    "use_rEx2 = pd.read_csv('use_riskEx2.csv')\n",
    "use_rEx3 = pd.read_csv('use_riskEx3.csv')\n",
    "use_rEx4 = pd.read_csv('use_riskEx4.csv')\n",
    "use_rEx5 = pd.read_csv('use_riskEx5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list stores dataframe references for iteration\n",
    "all_use_rEx = [use_rEx1, use_rEx2, use_rEx3, use_rEx4, use_rEx5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataframe 1 sorted by 'timeStamp'.\n",
      "Duplicate rows dropped from dataFrame  1\n",
      "\n",
      "Dataframe 2 sorted by 'timeStamp'.\n",
      "Duplicate rows dropped from dataFrame  2\n",
      "\n",
      "Dataframe 3 sorted by 'timeStamp'.\n",
      "Duplicate rows dropped from dataFrame  3\n",
      "\n",
      "Dataframe 4 sorted by 'timeStamp'.\n",
      "Duplicate rows dropped from dataFrame  4\n",
      "\n",
      "Dataframe 5 sorted by 'timeStamp'.\n",
      "Duplicate rows dropped from dataFrame  5\n",
      "\n",
      "+++ Dataframes Concatenated +++\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28964 entries, 0 to 28963\n",
      "Data columns (total 7 columns):\n",
      "author         28791 non-null object\n",
      "contents       28964 non-null object\n",
      "description    28960 non-null object\n",
      "publisher      28964 non-null object\n",
      "source_url     28964 non-null object\n",
      "timeStamp      28964 non-null object\n",
      "title          28954 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 1.5+ MB\n",
      "None \n",
      "\n",
      "\n",
      "DATAFRAME FEATURE OVERVIEW\n",
      "\n",
      "\tFeature:  author  \t  contains  7153 unique values.\n",
      "\tFeature:  contents  \t  contains  26418 unique values.\n",
      "\tFeature:  description  \t  contains  27716 unique values.\n",
      "\tFeature:  publisher  \t  contains  1753 unique values.\n",
      "\tFeature:  source_url  \t  contains  27909 unique values.\n",
      "\tFeature:  timeStamp  \t  contains  26989 unique values.\n",
      "\tFeature:  title  \t  contains  25460 unique values.\n",
      "\n",
      "\n",
      "\t\t\t+++++++++++++++++++++\n",
      " \t\t\t+ PROCESS COMPLETED +\n",
      " \t\t\t+++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "# object declared stores resulting cleaned, sorted and merged df\n",
    "use_r_Ex = merge_and_clean(all_use_rEx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting of concatenated df\n",
    "use_rEx_sort = df_sort(use_r_Ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of labels previously missed flag\n",
    "rm_forbidden = use_rEx_sort[use_rEx_sort['contents'] == 'Forbidden'].index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use remove_rows to remove observation from dataframe\n",
    "use_rEx = use_rEx_sort.drop(rm_forbidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>contents</th>\n",
       "      <th>description</th>\n",
       "      <th>publisher</th>\n",
       "      <th>source_url</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28601</td>\n",
       "      <td>28774</td>\n",
       "      <td>28770</td>\n",
       "      <td>28774</td>\n",
       "      <td>28774</td>\n",
       "      <td>28774</td>\n",
       "      <td>28764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7079</td>\n",
       "      <td>26417</td>\n",
       "      <td>27539</td>\n",
       "      <td>1740</td>\n",
       "      <td>27733</td>\n",
       "      <td>26813</td>\n",
       "      <td>25302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Scott Scanlon</td>\n",
       "      <td>If you are the site owner (or you manage this ...</td>\n",
       "      <td>Welcome to OVERNIGHT CYBERSECURITY, your daily...</td>\n",
       "      <td>Youbrandinc.com</td>\n",
       "      <td>https://www.bloomberg.com/news/articles/2018-0...</td>\n",
       "      <td>2018-03-26 12:00:00+00:00</td>\n",
       "      <td>6 things Australian traders will be talking ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1743</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>1730</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author                                           contents  \\\n",
       "count           28601                                              28774   \n",
       "unique           7079                                              26417   \n",
       "top     Scott Scanlon  If you are the site owner (or you manage this ...   \n",
       "freq             1743                                                 57   \n",
       "\n",
       "                                              description        publisher  \\\n",
       "count                                               28770            28774   \n",
       "unique                                              27539             1740   \n",
       "top     Welcome to OVERNIGHT CYBERSECURITY, your daily...  Youbrandinc.com   \n",
       "freq                                                    5             1730   \n",
       "\n",
       "                                               source_url  \\\n",
       "count                                               28774   \n",
       "unique                                              27733   \n",
       "top     https://www.bloomberg.com/news/articles/2018-0...   \n",
       "freq                                                    3   \n",
       "\n",
       "                        timeStamp  \\\n",
       "count                       28774   \n",
       "unique                      26813   \n",
       "top     2018-03-26 12:00:00+00:00   \n",
       "freq                           10   \n",
       "\n",
       "                                                    title  \n",
       "count                                               28764  \n",
       "unique                                              25302  \n",
       "top     6 things Australian traders will be talking ab...  \n",
       "freq                                                   43  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe overview\n",
    "use_rEx.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Write to csv__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_rEx.to_csv('use_rEx.csv', index_label = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **End Data Merging and Clean Up:** \n",
    "___\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
